Differential Analysis of State Donations by Ravin Kumar
========================================================
# Abstract
At time of writing it is November 2015 and the 2016 election year is only monnths away. Since there is no incumbent both parties are running multiple candidates. As a result my curiosity in way candidates fund their campaigns is higher than usual.

The Federal Election Commission requires that candidates publish details of the contributions publically. The dataset holds numerous interesting pieces of information, including contribution amount, donor size code, time of donation etc. I chose to analyze the contributions from California and Wisconsin only. This is an arbitrary choice, made largely because at different points in time I have been registered to vote in each state.



```{r echo=FALSE, message=FALSE, warning=FALSE, packages}
# Load all of the packages that you end up using
# in your analysis in this code chunk.

# Notice that the parameter "echo" was set to FALSE for this code chunk.
# This prevents the code from displaying in the knitted HTML output.
# You should set echo=FALSE for all code chunks in your file.

library(ggplot2)
library(dplyr)
library(lubridate)
```
```{r cache= TRUE, Load_the_Data}
# Need to specify columns due to trailing comma in files
cols = c("cmte_id","cand_id","cand_nm","contbr_nm","contbr_city","contbr_st",
         "contbr_zip","contbr_employer","contbr_occupation","contb_receipt_amt",
         "contb_receipt_dt","receipt_desc","memo_cd","memo_text","form_tp","file_num",
         "tran_id","election_tp", "DISCARD")

#Load and bind california dataframes
ca_df_2012 = read.csv(unzip("data/P00000001-CA_2012.zip"), col.names = cols, header = F, skip = 1)

ca_df_2016 = read.csv(unzip("data/P00000001-CA_2016.zip"), col.names = cols, header = F, skip = 1)

ca_df = rbind(ca_df_2012, ca_df_2016)

#Load and bind Wisconsin files
wi_df_2012 = read.csv(unzip("data/P00000001-WI_2012.zip"), col.names = cols, header = F, skip = 1)

#Some trouble with letters in zip code
#Removing occurence of letterL
wi_df_2012["contbr_zip"] = gsub("L", "", wi_df_2012[["contbr_zip"]])

#Load and bind 2016 data
wi_df_2016 = read.csv(unzip("data/P00000001-WI_2016.zip"), col.names = cols, header = F, skip = 1)

wi_df = rbind(wi_df_2012, wi_df_2016)

#Bind all into one dataframe
df = rbind(ca_df, wi_df)

#election_tp columns looks like G2012, Splitting into type and year
df["election_year"] = substr(df[["election_tp"]], 2,5)
df["election_type"] = substr(df[["election_tp"]], 0,1)
```

# Data Munging
Double checking columns of interest to ensure everything looks ok
```{r Additional Data Munging}
table(df["election_year"])

#2102 is likely a a typo. Converting to 2012
df[df["election_year"] == 2102, "election_year"] = 2012

#Removing all values from 2008
df = df[df["election_year"] != 2008,]
```
There are still 168 null values in the year column. Let's take a closer look
```{r null_Values}
head(df[df["election_year"] == "",])
summary(df[df["election_year"] == "",])
```
Seems like most of these are refunds. For now setting aside these nulls into their own dataframe for exploration later

```{r null_split}
df_null = df[df["election_year"] == "",]
df = df[df["election_year"] != ""]

```

Further exploration seems to show that the null values in the memo columns are represented as *
```{r find_na}
table(wi_df["memo_text"])
table(wi_df["memo_cd"])
```

```{r replace_na}

```

```{r Initial_Exploration}
```
#Questions
What candidate received the most contribution per state?  
What city contributes the most? What Zip Code?  
What employer?  
Occupation?  
Contributions per election type?  
Contribution cost averaged by population?  
Contributions over time?  

Do some comparisons for the states
Histogram or density plot of contribution amount per state
Contribution count over time for states

# Univariate Plots Section
```{r echo=FALSE, Univariate_Plots}

```

# Univariate Analysis

### What is the structure of your dataset?

### What is/are the main feature(s) of interest in your dataset?

### What other features in the dataset do you think will help support your investigation into your feature(s) of interest?

### Did you create any new variables from existing variables in the dataset?

### Of the features you investigated, were there any unusual distributions? Did you perform any operations on the data to tidy, adjust, or change the form of the data? If so, why did you do this?



# Bivariate Plots Section
```{r echo=FALSE, Bivariate_Plots}

```

# Bivariate Analysis

### Talk about some of the relationships you observed in this part of the investigation. How did the feature(s) of interest vary with other features in the dataset?

### Did you observe any interesting relationships between the other features (not the main feature(s) of interest)?

### What was the strongest relationship you found?




# Multivariate Plots Section

```{r echo=FALSE, Multivariate_Plots}

```

# Multivariate Analysis

### Talk about some of the relationships you observed in this part of the investigation. Were there features that strengthened each other in terms of looking at your feature(s) of interest?

### Were there any interesting or surprising interactions between features?

### OPTIONAL: Did you create any models with your dataset? Discuss the strengths and limitations of your model.

------

# Final Plots and Summary

### Plot One
```{r echo=FALSE, Plot_One}

```

### Description One


### Plot Two
```{r echo=FALSE, Plot_Two}

```

### Description Two


### Plot Three
```{r echo=FALSE, Plot_Three}

```

### Description Three

------

# Reflection

# Appendix
## File Links
http://www.fec.gov/disclosurep/pnational.do
ftp://ftp.fec.gov/FEC/Presidential_Map/2012/P00000001/P00000001-CA.zip  
ftp://ftp.fec.gov/FEC/Presidential_Map/2012/P00000001/P00000001-WI.zip  
ftp://ftp.fec.gov/FEC/Presidential_Map/2016/P00000001/P00000001-CA.zip  
ftp://ftp.fec.gov/FEC/Presidential_Map/2016/P00000001/P00000001-WI.zip  

#Project Rubric
https://docs.google.com/document/d/1L2Wwofs6D8Crd0QLZ1-RxBHlVoBZ3mec2xWgxrmUs5I/pub?embedded=true

#Examples
https://s3.amazonaws.com/udacity-hosted-downloads/ud651/diamondsExample.html  
https://s3.amazonaws.com/udacity-hosted-downloads/ud651/AtlanticHurricaneTracking.html  
https://s3.amazonaws.com/udacity-hosted-downloads/ud651/GeographyOfAmericanMusic.html  

#Dataset Reference
ftp://ftp.fec.gov/FEC/Presidential_Map/2016/DATA_DICTIONARIES/CONTRIBUTOR_FORMAT.txt  
https://docs.google.com/document/d/1qEcwltBMlRYZT-l699-71TzInWfk4W9q5rTCSvDVMpc/pub?embedded=true