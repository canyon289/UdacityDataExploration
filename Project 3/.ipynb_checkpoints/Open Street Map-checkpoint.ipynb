{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Open Street Map Data Wrangling\n",
    "\n",
    "## Abstract\n",
    "Open Street Map is a project to create a open source mapping of the world. It could most easily be understood as the Wikipedia of maps, where anyone in the world can add to the mapping dataset. The data provides a rich dataset, both interesting in the context of learning more about various geographic areas around the world, or from the data itself, such as how many people contributed to the dataset for a particular area. With any project reliant on human input though the data is sometimes inconsistent. \n",
    "\n",
    "### Los Angeles California\n",
    "Los Angeles California was chosen for two primary reasons. One is that Los Angeles is largest city in America, and the second most populous. It is very likely that there are more records in Los Angeles than most other American cities and it is also likely that there are more contributers. The second reason is that the I was born close to Los Angeles so to me it is a more interesting dataset.\n",
    "\n",
    "### Problems Encountered\n",
    "Three problems were found in the data file. All work is documented in the Cleaning Iteration Juptyer notebook\n",
    "  \n",
    "**Address Suffixes**  \n",
    "Street names in the dataset were inconsistently abbreviated, or not abbreviated. for instance \"Street\" was sometimes represnted as \"st.\" or \"st\" or in one occurence misspelled as \"sttreet\". Additionally other suffixes looked like zip codes or numbers. The obvious inconsistences were documented and changed before the addresses were loaded into mongodb\n",
    "\n",
    "**Postal Codes**\n",
    "A verification of the postcodes was made using MongoDB using the following query.\n",
    "> db.la_map.find({\\$and:[{\"address.postcode\":{\\$exists: true}},{\"address.postcode\" :{$not: /\\d+-?\\d+/}}]},{\"address.postcode\":1, \"pos\":1})\n",
    "\n",
    "<img src=\"postcodes.png\">\n",
    "\n",
    "This found all postcodes that did not conform to a **digit-digit** representation that's expected in America. Of the non conforming values two distinct issues arised. The first was fairly straightforward, someone labeled the post codes as Disneyland for 10 nodes. The fix was fairly simple, just replaced this value with Disneylands actual postcode. However there were four other instances where Ca, California's abbreviation, or the city was used as a post code. For these the actual post code was imputed using the latitude and longitude of the node. These were then added to a python dictionary and replaced as the JSON was processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zip_mapping = {( 34.0572495, -118.2751067):90057, (33.6561412, -117.7536445):92618,\\\n",
    "               (34.375206, -118.5295727):91321, (34.2623343, -118.3200911):91040}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Ideas\n",
    "\n",
    "#### Import establishments from Environmental Health Data\n",
    "Los Angeles rates every establishment on a regular basis which means a public list of the name, type of facility, and address of all these dining facilities are available and of high quality. An import of this dataset could be performed to add many relevant points of interest to OSM's dataset. \n",
    "\n",
    "Unfortunately this is only limited to the very specific region of Los Angeles, and does not provide a consistent solution that is able to used globally. Another issue is that while mass imports may sound simple, they can cause trouble in their initial import and reimports to update the data over time may not be possible. Issues arising from the TIGER import would likely occur with an Environment Health Data import as well.\n",
    "\n",
    "#### Machine Learning to autocorrect or suggest fixes\n",
    "It would be possible to create a machine learning algorithm which can predict attributes, or determine which attributes may be incorrect. For instance a machine learning algorithm could perform an analysis to determine zip codes. If one node has different postcode than all its surrounding nodes a clustering analysis may detect this. Similarly a machine learning algorithm could perhaps learn where nodes of interest are likely to exist.\n",
    "\n",
    "Similar to the issue above however this Machine Learning algorithm would have to be very generalizable to work across all the regions of the world, as postal codes and points of interest vary by country. Additionally the amount of human and computational resources to train and develop a model may be prohibitive for an effort that is largely sustained by donations. It also may stand against the goals of the organization, which on it's webpage proclaims \"OpenStreetMap emphasizes local knowledge\" and OpenStreetMap is built by a community of mappers that contribute and maintain data\". It may go against the culture of the organization to have an algorithm contribute data.\n",
    "\n",
    "\n",
    "## Conclusion\n",
    "The LA dataset is quite large, over 1 gigabyte as a JSON, and took numerous hours to process on my laptop. When using Mongodb over Python parsing however the results were much quicker, and I would expect that when MongoDB is used on an external server the results are even quicker.\n",
    "\n",
    "The OSM street map data for Los Angeles was suprisingly clean, most fields were correct. However it is evident that multiple people are contributing as small differences such as **ave** vs **ave.** and mistaken postcodes. However in general it is quite amazing that without financial incentive Open Street Map has been able to create such a robust dataset of the things around us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "The map data was initially downloaded from MapZen as a bz2 file. The data was then preprocessed into a json file using Python, before being imported into a MongoDB instance for further analysis.\n",
    "\n",
    "## Data Overiew\n",
    "\n",
    "### Verify Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_location = \"data\\los-angeles_california.osm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from programs import tags\n",
    "tag = tags.process_map(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lower': 1804949, 'lower_colon': 2122407, 'other': 176260, 'problemchars': 0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the 4,103,616 tags luckily none of them contain any of characters labeled as problem characters in the Lesson 6 example.\n",
    "\n",
    "### Number of contributors and elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from programs import users\n",
    "users, ids = users.process_map(file_location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Number of Users: 3026     Number of Ids: 5952617'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Number of Users: {0}     Number of Ids: {1}\".format(len(users),len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['54466833', '2170105523', '123699544', '7318336', '1118375156']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(ids)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of the millions of people that have visited or live in LA it seems that only 3026 people are responsible for all the points in the LA Open Street Mapb Project. Further analysis will be done after the MongoDB database has been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Nodes and Ways\n",
    "A function was added to the data module which counts the number of ways and nodes elements in the original LA osm file. We'll be using this counter later to verify that import into Mongodb was successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from programs import data\n",
    "count = data.count_elements(file_location)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create json file\n",
    "For import into Mongodb, the osm file, an XML type file, will be converted into a json using python. During the conversion process street names are checked and converted. The list of conversations was generated manually by reviewing a list of all street suffixes to check for repeats or typos. Processing the map takes significant resources and was precomputed outside of this notebook.\n",
    "\n",
    "| File Type | Size (mb) |\n",
    "|-----------|-----------|\n",
    "| bz2       | 89        |\n",
    "| OSM       | 1211      |\n",
    "| json      | 1568      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if True == False: #Prevents execution\n",
    "    data.process_map(file_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MongoDB\n",
    "Mongodb is a popular NoSQL database that stores its data in collections of documents. Documents have a flexible schema, which works well for the OpenStreetMap data as not every node and way has the same \"columns\". If the Open Street Map data was to be stored in a tabular databases many fields would be null, for instance \"Outside Seating\" would be irrelevant for most businsses. Additionally adding extra data would be burdensome as new columns would have to be added to an ever growing table.\n",
    "\n",
    "### Loading Data\n",
    "The JSON file generated by our previous Python method needs to initially be loaded into Mongodb using the following command in the terminal\n",
    "\n",
    ">mongoimport --db test --collection la_map --file los-angeles_california.osm.json\n",
    "\n",
    "After some exploratory analysis it was found that there were further issues in the OSM database. After making the necessary fixes the following command was used to load a collection in the final database.\n",
    "\n",
    ">mongoimport --db test --collection la_map --file los-angeles_california.osm.json\n",
    "\n",
    "\n",
    "## Queries\n",
    "### Loading Python Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client.final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifying all documents imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5953758"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.la_map.find().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting Number of Elements in entire collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45403693\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for document in db.la_map.find():\n",
    "    counter += len(document)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of Nodes and Ways\n",
    "The Lesson 6 files initially used the **type** attribute to denote nodes and ways. After an initial exploration it was found that the OSM data already contained a type field. As was such another unused attribute named **osm_type** was created to denote nodes and ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['node', 'way']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.la_map.distinct(\"osm_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Count': 579785, '_id': 'way'}, {'Count': 5373973, '_id': 'node'}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.la_map.aggregate([{\"$group\":{\"_id\":\"$osm_type\", \"Count\":{\"$sum\":1}}}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what types of cuisines are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['burger',\n",
       " 'japanese',\n",
       " 'american',\n",
       " 'thai',\n",
       " 'korean',\n",
       " 'vietnamese',\n",
       " 'sushi',\n",
       " 'mexican',\n",
       " 'italian',\n",
       " 'roast_beef',\n",
       " 'coffee',\n",
       " 'sandwich',\n",
       " 'hawaiian',\n",
       " 'ice_cream',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'fish_and_chips',\n",
       " 'chinese',\n",
       " 'steak_house',\n",
       " 'chicken;mexican',\n",
       " 'chicken',\n",
       " 'Japanese Ramen',\n",
       " 'Northern Chinese',\n",
       " 'taiwanese',\n",
       " 'indian',\n",
       " 'mediterranean',\n",
       " 'cantonese',\n",
       " 'regional',\n",
       " 'coffee_shop',\n",
       " 'french',\n",
       " 'gastropub',\n",
       " 'noodle',\n",
       " 'asian',\n",
       " 'peruvian',\n",
       " 'greek',\n",
       " 'steak;seafood',\n",
       " 'italian;mediterranean',\n",
       " 'deli',\n",
       " 'burger;american',\n",
       " 'barbecue',\n",
       " 'american;bakery',\n",
       " 'seafood',\n",
       " 'Californian',\n",
       " 'breakfast',\n",
       " 'burger;mexican',\n",
       " 'american;brewpub',\n",
       " 'garlic',\n",
       " 'indonesian',\n",
       " 'pizza;chicken',\n",
       " 'catering',\n",
       " 'juice',\n",
       " 'sushi;steak;japanese',\n",
       " 'seafood;steak',\n",
       " 'mexican;pizza',\n",
       " 'seafood;sushi;steak',\n",
       " 'greek;burger',\n",
       " 'seafood;california',\n",
       " 'chinese;sushi',\n",
       " 'seafood;steak;hawaiian',\n",
       " 'sushi;japanese;steak',\n",
       " 'mexican;steak;seafood',\n",
       " 'sushi;california',\n",
       " 'chicken;ice_cream',\n",
       " 'seafood;brewpub',\n",
       " 'hotdog',\n",
       " 'Taiwanese',\n",
       " 'steak',\n",
       " 'sausage',\n",
       " 'armenian',\n",
       " 'mexican; seafood',\n",
       " 'ice_cream;burger',\n",
       " 'Vietnamise',\n",
       " 'cuban',\n",
       " 'chinese,_taiwanese',\n",
       " 'italian;pizza',\n",
       " 'bagel',\n",
       " 'Diner',\n",
       " 'fusion',\n",
       " 'bakery',\n",
       " 'vegetarian',\n",
       " 'mexican;hawaiian',\n",
       " 'german',\n",
       " 'Pizza',\n",
       " 'sichuan',\n",
       " 'russian',\n",
       " 'English',\n",
       " 'american;mexican',\n",
       " 'mexican;mexican_seafood',\n",
       " 'Xin Jiang BBQ',\n",
       " 'yogurt',\n",
       " 'burger;ice_cream',\n",
       " 'brazilian',\n",
       " 'vegan',\n",
       " 'buffet',\n",
       " 'pizza;pasta;burger',\n",
       " 'international',\n",
       " 'spanish',\n",
       " 'afghan',\n",
       " 'frozen_yogurt',\n",
       " 'kebab',\n",
       " 'middle_eastern',\n",
       " 'mongolian',\n",
       " 'sub',\n",
       " 'salad',\n",
       " 'German/Swiss',\n",
       " 'Juice_Bar',\n",
       " 'coffee_shop,_sandwiches, ice cream floats, root beer',\n",
       " 'Cuban',\n",
       " 'pretzels',\n",
       " 'healthy',\n",
       " 'Pizza,_Burgers,_Breakfast',\n",
       " 'Vietnamese_',\n",
       " 'persian',\n",
       " 'Burger_Bar',\n",
       " 'El_Salvadorian',\n",
       " 'Chicken_Sandwiches',\n",
       " 'Frozen_yogurt',\n",
       " 'sushi,_asian',\n",
       " 'sandwiches',\n",
       " 'Mexican,_Indian,_American',\n",
       " 'sushi,_sashimi,_teriyaki',\n",
       " 'mexican,_asian,_fusion',\n",
       " 'korean_bbq',\n",
       " 'Bagel',\n",
       " 'Pizza,_Italian,_sandwiches, pasta',\n",
       " 'Frozen_Yogurt,_Desert,ice cream',\n",
       " 'Chinese,_Thai',\n",
       " 'donuts',\n",
       " 'fondue',\n",
       " 'Chinese_(Taiwanese)',\n",
       " 'Middle_Eastern_Cuisine',\n",
       " 'hot_dog',\n",
       " 'funnel_cake',\n",
       " 'Smoothies',\n",
       " 'cafe',\n",
       " 'pancake',\n",
       " 'Bakery',\n",
       " 'Latin',\n",
       " 'Healthy',\n",
       " 'New_York_Pizza',\n",
       " 'indian; pakistani',\n",
       " 'Brewery,_Pub,_American',\n",
       " 'latin_american',\n",
       " 'chinese_All_you_can_eat',\n",
       " 'BBQ_All_you_can_eat',\n",
       " 'american_All_you_can_eat',\n",
       " 'chinese,_Hawaiian_BBQ',\n",
       " 'indian,_vegetarian',\n",
       " 'mexican_[cafeteria_style,_low_cost,_family_food]',\n",
       " 'mexican,_vegetarian',\n",
       " 'international,_vegan,_salads,_vegetarian',\n",
       " 'boba',\n",
       " 'Mongolian_BBQ',\n",
       " 'Dim_Sum,_Cantonese',\n",
       " 'Cantonese,_Dim_Sum,_Seafood',\n",
       " 'Taiwan,_Chinese',\n",
       " 'Cantonese,_Dim_Sum,_Chinese',\n",
       " 'chinese,_noodle',\n",
       " 'noodle,_Taiwanese,_Chinese',\n",
       " 'Chinese,_Cantonese',\n",
       " 'Seafood,_Chinese',\n",
       " 'Cantonese',\n",
       " 'Healthy_Delicious',\n",
       " 'american,breakfast',\n",
       " 'italian,pizza',\n",
       " 'Yogurt',\n",
       " 'Mexican',\n",
       " 'Asian',\n",
       " 'Seafood_+_Raw_Bar',\n",
       " 'moroccan',\n",
       " 'steakhouse',\n",
       " 'Cheesecake_Factory',\n",
       " 'American_Breakfast',\n",
       " 'Pho',\n",
       " 'Persian',\n",
       " 'sea_food',\n",
       " 'hot_dogs',\n",
       " 'Baked_Goods',\n",
       " 'fast_food',\n",
       " 'country',\n",
       " 'burger;mexican;breakfast',\n",
       " 'soup;salad;pasta',\n",
       " 'steak;chicken;seafood;pasta',\n",
       " 'sandwich;pizza;pasta;soup;salad',\n",
       " 'pancakes;breakfast;burger;sandwich;regional',\n",
       " 'american;steak;chicken;pasta;seafood',\n",
       " 'Chinese,_Szechuan',\n",
       " 'burger;sandwich;breakfast',\n",
       " 'italian;soup;bread',\n",
       " 'fish',\n",
       " 'cake',\n",
       " 'pasta',\n",
       " 'Korean_All_You Can Eat',\n",
       " 'french;american',\n",
       " 'burger;deli;mexican;breakfast',\n",
       " 'breakfast;sandwhich;burger',\n",
       " 'burger;salad;soup;mexican',\n",
       " 'chicken;breakfast;dessert',\n",
       " 'America',\n",
       " 'Pies,coffee,desserts',\n",
       " 'New_Orleans',\n",
       " 'Japanese_Fusion',\n",
       " 'jewish',\n",
       " 'northern_chinese',\n",
       " 'Twists',\n",
       " 'Chinese',\n",
       " 'burger,_hot_dogs',\n",
       " 'pizza,_burger,_american',\n",
       " 'Upscale_comfort_food',\n",
       " 'Upscale_Comfort_Food',\n",
       " 'smoothies',\n",
       " 'Korean_BBQ',\n",
       " 'chinese,seafood',\n",
       " 'taco',\n",
       " 'cajun',\n",
       " 'steakhouse,_italian,_mediterranean',\n",
       " '3',\n",
       " 'burger;chicken',\n",
       " 'seafood,_Dim_sum,_Cantonese',\n",
       " 'bar',\n",
       " 'Juice_Smoothie',\n",
       " 'Fried_Chicken',\n",
       " 'Fast-Food',\n",
       " 'Southeast_Asian',\n",
       " 'south_african',\n",
       " 'BBQ',\n",
       " 'Cajun-Creole',\n",
       " 'burger_mexican_breakfast',\n",
       " 'filipino']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.la_map.distinct(\"cuisine\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Number of Coffee Shops\n",
    "Reading through the list I realized that I am actually very curious about the coffee shops in Los Angeles. Google Maps returns many many results, as does Yelp, so I would like to see if that's reflected here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "174"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.la_map.find({\"cuisine\":{\"$regex\": u\".*coffee.*\"}}).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these coffee shops I would like to see how many users submitted entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'_id': 'Brian@Brea', 'contributions': 19},\n",
       " {'_id': 'andrewpmk', 'contributions': 7},\n",
       " {'_id': 'ponzu', 'contributions': 7},\n",
       " {'_id': 'kisaa', 'contributions': 7},\n",
       " {'_id': 'Clarke22', 'contributions': 6},\n",
       " {'_id': 'youngbasedallah', 'contributions': 4},\n",
       " {'_id': 'DMaximus', 'contributions': 4},\n",
       " {'_id': 'michael_kirk', 'contributions': 3},\n",
       " {'_id': 'freewillisanillusion', 'contributions': 3},\n",
       " {'_id': 'kdano', 'contributions': 3},\n",
       " {'_id': 'bondah', 'contributions': 3},\n",
       " {'_id': 'Oleg Shalaev', 'contributions': 3},\n",
       " {'_id': 'release_candidate', 'contributions': 3},\n",
       " {'_id': 'thevirginian', 'contributions': 3},\n",
       " {'_id': 'StellanL', 'contributions': 3},\n",
       " {'_id': 'jgpacker', 'contributions': 3},\n",
       " {'_id': 'sankeytm', 'contributions': 2},\n",
       " {'_id': 'palewire', 'contributions': 2},\n",
       " {'_id': 'pverik', 'contributions': 2},\n",
       " {'_id': 'Peejster', 'contributions': 2}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(db.la_map.aggregate([{\"$match\":{\"cuisine\":{\"$regex\": u\".*coffee.*\"}}},\n",
    "                         {\"$group\": {\"_id\":\"$created.user\", \"contributions\": {\"$sum\":1}}},\n",
    "                         {\"$sort\":{\"contributions\":-1}},\n",
    "                         {\"$limit\":20}\n",
    "                         ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "## Lesson 6 Exercises\n",
    "All exercises are located in the programs folder. Modifications and extra functions outside of the required exercises are included for use with the LA OSM file. Additional modules exist for data munging the LA OSM file before conversion\n",
    "\n",
    "## Reference\n",
    "Map Source - https://mapzen.com/data/metro-extracts  \n",
    "MongoDB Manual - https://docs.mongodb.org/manual/  \n",
    "FourSquare and OSM - https://www.mapbox.com/blog/connecting-foursquare-openstreetmap/  \n",
    "Los Angeles County Department of Public Health - https://ehservices.publichealth.lacounty.gov/ezsearch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
